#!/usr/bin/env python3

import urllib.parse
import argparse
import socket
import ssl
import re

DEFAULT_SERVER = "proj5.3700.network"
DEFAULT_PORT = 443

# Parses the header data, extracts the response code and puts the rest into a dict
def parse_headers(headers_data):
    headers = {}

    # Parsing the header data and splitting it appropriately by the Response-Code
    headers_data = headers_data.split("\r\n")
    response_type = headers_data[0]
    response_code = int(response_type.split(' ')[1])
    headers['Response-Code'] = response_code
    headers_data = headers_data[1:]
    for header in headers_data:
        if len(header) == 0:
            continue
        header_split = header.split(':', 1)

        # Get the Set-Cookie data (session id, csrftokens, etc.)
        if header_split[0] == 'Set-Cookie' and ('sessionid' in header_split[1]):
            session_id = re.findall(r'sessionid=([a-zA-Z0-9]+)', header)[0]
            headers['session-id'] = session_id
        elif header_split[0] == 'Set-Cookie' and ('csrftoken' in header_split[1]):
            csrf_token = re.findall(r'csrftoken=([a-zA-Z0-9]+)', header)[0]
            headers['csrftoken'] = csrf_token
        else:
            headers[header_split[0]] = header_split[1]

    return response_code, headers


# Finds the csrfmiddlware token by parsing the html_data
def get_csrf_middleware(html_data, headers):
    split_by_line = html_data.splitlines()
    for line in split_by_line:
        if 'csrfmiddlewaretoken' in line:
            middleware_token = re.findall(r'value="([^"]*)"', line)[0]
            headers['csrfmiddlewaretoken'] = middleware_token
    return headers

# Returns the get_request_str
def get_request_str(host, dir='/'):
    request = f"GET {dir} HTTP/1.1\r\n"
    request += f"Host: {host}\r\n"
    request += f"Connection: keep-alive\r\n"
    request += "\r\n"
    return request

# get_request but it uses cookies
def get_request_cookies(host, dir, cookies):
    request = f"GET {dir} HTTP/1.1\r\n"
    request += f"Host: {host}\r\n"
    request += f"Connection: keep-alive\r\n"
    request += f"Cookie: csrftoken={cookies['csrftoken']}; sessionid={cookies['session-id']}\r\n"
    request += "\r\n"
    return request

# Generates a post request string, attaches the appropriate headers to the request
def post_request_str(host, username, password, headers, cmd='/'):
    # Username, password, and csrfmiddlwaretoken information
    data = urllib.parse.urlencode({
        "username": username,
        "password": password,
        "csrfmiddlewaretoken": headers['csrfmiddlewaretoken'] if 'csrfmiddlewaretoken' in headers else "",
    }).encode()

    # The command for a post request
    request = f"POST {cmd} HTTP/1.1\r\n"
    request += f"Host: {host}\r\n"
    request += "Content-Type: application/x-www-form-urlencoded\r\n"
    request += f"Content-Length: {len(data)}\r\n"
    request += f"Connection: keep-alive\r\n"
    request += f"Cookie: csrftoken={headers['csrftoken']}; sessionid={headers['session-id']}\r\n"
    request += "\r\n"
    request += data.decode() + "\r\n"
    return request

# Sends the request
def send_request(mysocket, request):
    mysocket.send(request.encode('ascii'))
    response = b""

    # First we read all the headers: stop when we see the line break
    while True:
        data = mysocket.recv(1)
        response += data
        if b'\r\n\r\n' in response:
            break

    response = response.decode('ascii')
    _, headers = parse_headers(response)

    # Receive the body of the request once we know how long it is/should be
    body_length = int(headers['Content-Length'])
    body = mysocket.recv(body_length)
    body = body.decode('ascii')

    return headers, body

# Class to crawl the website
class Crawler:
    def __init__(self, args):
        self.server = args.server
        self.port = args.port
        self.username = args.username
        self.password = args.password
        self.encrypt = True
        self.links = []
        self.flags = set()
        self.seen = set()

        self.cookies = {}
        self.seen_counter = 0

    def run(self):
        # Init the socket
        mysocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        if self.encrypt:
            context = ssl.create_default_context()
            mysocket = context.wrap_socket(mysocket, server_hostname=self.server)
        mysocket.connect((self.server, self.port))

        # Login before we can start parsing.
        mysocket = self.handle_login(mysocket)

        # We until we find all five flags
        while len(self.links) > 0 and len(self.flags) < 5:

            # We reconnect after some amount of requests
            if self.seen_counter >= 5000:
                self.seen_counter = 0
                mysocket.close()
                self.run()
                return

            current_link = self.links.pop()

            # Check that we have not been to this link before and is well-formed.
            if current_link not in self.seen and '/fakebook/' in current_link:
                self.seen.add(current_link)
                self.seen_counter += 1
                
                request = get_request_cookies(self.server, current_link,
                                              self.cookies)
                headers, body = send_request(mysocket, request)
                response_code = headers['Response-Code']
                if response_code == 302:
                    # If we receive a 302, then request again using the new URL
                    self.links.append(headers['Location'])
                    continue
                elif response_code == 403 or response_code == 404:
                    # If we receive a 403 or a 404 we disregard the current link
                    continue
                elif response_code == 503:
                    # If we receive a 503, we need to retry the current link
                    self.seen.remove(current_link)
                    self.links.append(current_link)
                elif response_code == 200:
                    # If we receive a 200, we can look for flags and add new links to the stack
                    self.get_links(body)
                    self.look_for_flags(body)

        for flag in self.flags:
            print(flag)

    # Handles the login
    def handle_login(self, mysocket):

        # Go to the login website initially to get cookies
        request = get_request_str(self.server, '/accounts/login/?next=/fakebook/')
        headers, body = send_request(mysocket, request)
        get_csrf_middleware(body, headers)

        # Send post request to the login website
        request = post_request_str(self.server, self.username, self.password, headers,
                                   "/accounts/login/?next=/fakebook/")
        headers, body = send_request(mysocket, request)

        # Remember the cookies info
        self.cookies['csrftoken'] = headers['csrftoken']
        self.cookies['session-id'] = headers['session-id']

        # Go to the new location and get the initial links.
        request = get_request_cookies(self.server, headers['Location'], headers)
        headers, body = send_request(mysocket, request)
        self.get_links(body)
        self.look_for_flags(body)

        return mysocket

    # Finds all the links on the webpage
    def get_links(self, html_data):
        split_by_line = html_data.splitlines()
        for line in split_by_line:
            if 'href=' in line and 'fakebook' in line:
                link = re.findall(r'href="([^"]*)"', line)[0]
                if link not in self.links:
                    self.links.append(link)

    # Look for any flags on the webpage
    def look_for_flags(self, html_data):
        split_by_line = html_data.splitlines()
        for line in split_by_line:
            if 'secret_flag' in line:
                link = re.findall(r"FLAG: ([A-Za-z0-9]{64})", line)[0]
                self.flags.add(link)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='crawl Fakebook')
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()
    sender = Crawler(args)
    sender.run()